"""
DataLake ì„œë¹„ìŠ¤ ìƒíƒœ ë° DB ì—°ê²° í…ŒìŠ¤íŠ¸
1. ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬
2. PostgreSQL ì—°ê²°
3. Redis ì—°ê²°
4. Kafka ì—°ê²°
"""

import pytest
import requests
import psycopg2
import redis
from kafka import KafkaProducer
import time


class TestServiceHealth:
    """ì„œë¹„ìŠ¤ ìƒíƒœ ë° DB ì—°ê²° í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    @pytest.mark.unit
    def test_datalake_api_health(self, base_url):
        """DataLake API ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬"""
        response = requests.get(f"{base_url}/healthz", timeout=10)
        
        assert response.status_code == 200, f"ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {response.status_code}"
        
        data = response.json()
        assert data["status"] == "healthy", f"ì„œë¹„ìŠ¤ ìƒíƒœê°€ healthyê°€ ì•„ë‹˜: {data['status']}"
        assert data["service"] == "datalake", f"ì„œë¹„ìŠ¤ëª…ì´ datalakeê°€ ì•„ë‹˜: {data['service']}"
    
    @pytest.mark.unit
    def test_datalake_root_endpoint(self, base_url):
        """DataLake ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""
        response = requests.get(f"{base_url}/", timeout=10)
        
        assert response.status_code == 200, f"ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ì‹¤íŒ¨: {response.status_code}"
        
        data = response.json()
        assert "message" in data, "ì‘ë‹µì— message í•„ë“œê°€ ì—†ìŒ"
        assert "DataLake Service" in data["message"], f"ì˜ëª»ëœ ë©”ì‹œì§€: {data['message']}"
    
    @pytest.mark.integration
    def test_postgresql_connection(self, db_config):
        """PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            conn = psycopg2.connect(**db_config)
            cursor = conn.cursor()
            
            # ë²„ì „ í™•ì¸
            cursor.execute("SELECT version();")
            version = cursor.fetchone()
            
            assert version is not None, "PostgreSQL ë²„ì „ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ"
            assert "PostgreSQL" in version[0], f"PostgreSQLì´ ì•„ë‹˜: {version[0]}"
            
            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            cursor.execute("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
                ORDER BY table_name;
            """)
            tables = cursor.fetchall()
            
            # í•„ìˆ˜ í…Œì´ë¸” í™•ì¸
            table_names = [table[0] for table in tables]
            expected_tables = ['realtime', 'alert']
            
            for expected_table in expected_tables:
                assert expected_table in table_names, f"í•„ìˆ˜ í…Œì´ë¸” {expected_table}ì´ ì—†ìŒ"
            
            cursor.close()
            conn.close()
            
        except Exception as e:
            pytest.fail(f"PostgreSQL ì—°ê²° ì‹¤íŒ¨: {e}")
    
    @pytest.mark.integration
    def test_redis_connection(self, redis_config):
        """Redis ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            r = redis.Redis(**redis_config)
            
            # PING í…ŒìŠ¤íŠ¸
            response = r.ping()
            assert response is True, "Redis PING ì‹¤íŒ¨"
            
            # ê°„ë‹¨í•œ ë°ì´í„° ì“°ê¸°/ì½ê¸° í…ŒìŠ¤íŠ¸
            test_key = "datalake_test_key"
            test_value = "datalake_test_value"
            
            r.set(test_key, test_value)
            retrieved_value = r.get(test_key)
            
            assert retrieved_value.decode('utf-8') == test_value, "Redis ë°ì´í„° ì½ê¸°/ì“°ê¸° ì‹¤íŒ¨"
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
            r.delete(test_key)
            
        except Exception as e:
            pytest.fail(f"Redis ì—°ê²° ì‹¤íŒ¨: {e}")
    
    @pytest.mark.integration
    def test_kafka_connection(self, kafka_config):
        """Kafka ë¸Œë¡œì»¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            producer = KafkaProducer(
                bootstrap_servers=kafka_config['bootstrap_servers'],
                request_timeout_ms=10000
            )
            
            # ì—°ê²° í™•ì¸
            assert producer.bootstrap_connected(), "Kafka ë¸Œë¡œì»¤ì— ì—°ê²°í•  ìˆ˜ ì—†ìŒ"
            
            # í† í”½ ëª©ë¡ í™•ì¸
            from kafka.admin import KafkaAdminClient, ConfigResource, ConfigResourceType
            
            admin_client = KafkaAdminClient(
                bootstrap_servers=kafka_config['bootstrap_servers']
            )
            
            topics = admin_client.list_topics()
            
            # í•„ìˆ˜ í† í”½ í™•ì¸
            expected_topics = ['fire-iot.anomaly-detected', 'fire-iot.sensorDataSaved']
            
            for expected_topic in expected_topics:
                assert expected_topic in topics, f"í•„ìˆ˜ í† í”½ {expected_topic}ì´ ì—†ìŒ"
            
            producer.close()
            admin_client.close()
            
        except Exception as e:
            pytest.fail(f"Kafka ì—°ê²° ì‹¤íŒ¨: {e}")
    
    @pytest.mark.integration
    def test_all_services_healthy(self, base_url, db_config, redis_config, kafka_config):
        """ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í†µí•© í…ŒìŠ¤íŠ¸"""
        # API ì„œë¹„ìŠ¤ í™•ì¸
        api_healthy = False
        try:
            response = requests.get(f"{base_url}/healthz", timeout=5)
            api_healthy = response.status_code == 200
        except:
            pass
        
        # DB ì—°ê²° í™•ì¸
        db_healthy = False
        try:
            conn = psycopg2.connect(**db_config)
            conn.close()
            db_healthy = True
        except:
            pass
        
        # Redis ì—°ê²° í™•ì¸
        redis_healthy = False
        try:
            r = redis.Redis(**redis_config)
            r.ping()
            redis_healthy = True
        except:
            pass
        
        # Kafka ì—°ê²° í™•ì¸
        kafka_healthy = False
        try:
            producer = KafkaProducer(bootstrap_servers=kafka_config['bootstrap_servers'])
            producer.close()
            kafka_healthy = True
        except:
            pass
        
        # ëª¨ë“  ì„œë¹„ìŠ¤ê°€ ì •ìƒì´ì–´ì•¼ í•¨
        assert api_healthy, "DataLake API ì„œë¹„ìŠ¤ê°€ ì •ìƒì´ ì•„ë‹˜"
        assert db_healthy, "PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ê°€ ì •ìƒì´ ì•„ë‹˜"
        assert redis_healthy, "Redisê°€ ì •ìƒì´ ì•„ë‹˜"
        assert kafka_healthy, "Kafkaê°€ ì •ìƒì´ ì•„ë‹˜"
    
    @pytest.mark.slow
    def test_service_stability(self, base_url):
        """ì„œë¹„ìŠ¤ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸ (ì—°ì† ìš”ì²­)"""
        # 10ë²ˆ ì—°ì†ìœ¼ë¡œ í—¬ìŠ¤ì²´í¬ ìš”ì²­
        for i in range(10):
            response = requests.get(f"{base_url}/healthz", timeout=5)
            assert response.status_code == 200, f"ì—°ì† ìš”ì²­ {i+1}ë²ˆì§¸ ì‹¤íŒ¨: {response.status_code}"
            time.sleep(0.1)  # 100ms ê°„ê²©
    
    @pytest.mark.integration
    def test_service_response_time(self, base_url):
        """ì„œë¹„ìŠ¤ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
        start_time = time.time()
        response = requests.get(f"{base_url}/healthz", timeout=10)
        end_time = time.time()
        
        response_time = end_time - start_time
        
        assert response.status_code == 200, "ì„œë¹„ìŠ¤ ì‘ë‹µ ì‹¤íŒ¨"
        assert response_time < 1.0, f"ì‘ë‹µ ì‹œê°„ì´ ë„ˆë¬´ ê¹€: {response_time:.3f}ì´ˆ (1ì´ˆ ì´ˆê³¼)"
        
        # ì‘ë‹µ ì‹œê°„ì´ 100ms ì´í•˜ì¸ì§€ í™•ì¸ (ë¡œì»¬ í™˜ê²½ ê¸°ì¤€)
        if response_time < 0.1:
            print(f"âœ… ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„: {response_time:.3f}ì´ˆ")
        elif response_time < 0.5:
            print(f"âš ï¸ ë³´í†µ ì‘ë‹µ ì‹œê°„: {response_time:.3f}ì´ˆ")
        else:
            print(f"ğŸŒ ëŠë¦° ì‘ë‹µ ì‹œê°„: {response_time:.3f}ì´ˆ")
