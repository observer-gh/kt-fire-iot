import asyncio
import logging
from datetime import datetime
from typing import Optional
from .mock_server_client import MockServerClient
from .processor import DataProcessor
from .storage_service import StorageService
from .publisher import KafkaPublisher
from .config import settings

logger = logging.getLogger(__name__)

class MockDataScheduler:
    """Mock Serverì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self, storage_service: StorageService, kafka_publisher: KafkaPublisher):
        self.storage_service = storage_service
        self.kafka_publisher = kafka_publisher
        self.mock_server_client = MockServerClient()
        self.is_running = False
        self.task: Optional[asyncio.Task] = None
        self.data_fetch_interval = settings.mock_server_data_fetch_interval_seconds
        
    async def start(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."""
        if self.is_running:
            logger.warning("Mock Data Schedulerê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.")
            return
        
        self.is_running = True
        self.task = asyncio.create_task(self._run_scheduler())
        logger.info(f"Mock Data Schedulerê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. í´ë§ ê°„ê²©: {self.data_fetch_interval}ì´ˆ")
    
    async def stop(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì¤‘ì§€í•©ë‹ˆë‹¤."""
        if not self.is_running:
            return
        
        self.is_running = False
        if self.task:
            self.task.cancel()
            try:
                await self.task
            except asyncio.CancelledError:
                pass
        logger.info("Mock Data Schedulerê°€ ì¤‘ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    async def _run_scheduler(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”ì¸ ë£¨í”„"""
        while self.is_running:
            try:
                await self._process_mock_data()
                await asyncio.sleep(self.data_fetch_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Mock Data Scheduler ì˜¤ë¥˜: {e}")
                await asyncio.sleep(10)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ 10ì´ˆ ëŒ€ê¸°
    
    async def _process_mock_data(self):
        """Mock Serverì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            logger.info("Mock Serverì—ì„œ ë°ì´í„°ë¥¼ í´ë§í•˜ëŠ” ì¤‘...")
            
            # Mock Server ìƒíƒœ í™•ì¸
            if not await self.mock_server_client.health_check():
                logger.warning("Mock Serverê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ìŒ í´ë§ê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
                return
            
            # ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì„¤ì •ê°’ ì‚¬ìš©)
            from .config import settings
            stream_count = settings.mock_server_stream_data_count
            raw_data_list = await self.mock_server_client.get_stream_data(stream_count)
            
            if not raw_data_list:
                logger.info("Mock Serverì—ì„œ ë°ì´í„°ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return
            
            logger.info(f"Mock Serverì—ì„œ {len(raw_data_list)}ê°œì˜ ë°ì´í„°ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤.")
            
            # ê° ë°ì´í„°ë¥¼ ì²˜ë¦¬
            processed_count = 0
            anomaly_count = 0
            
            for raw_data in raw_data_list:
                try:
                    # ë°ì´í„° ì²˜ë¦¬
                    processed_data = DataProcessor.process_sensor_data(raw_data)
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                    save_success = self.storage_service.save_sensor_data(processed_data)
                    if not save_success:
                        logger.error(f"Mock ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {raw_data.equipment_id}")
                        continue
                    
                    processed_count += 1
                    
                    # ì´ìƒì¹˜ íƒì§€ ë° ì´ë²¤íŠ¸ ë°œí–‰
                    if processed_data.is_anomaly:
                        anomaly_count += 1
                        await self.kafka_publisher.publish_anomaly_detected(processed_data)
                        logger.info(f"ğŸš¨ Mock ë°ì´í„° ì´ìƒì¹˜ íƒì§€: {processed_data.equipment_id} - {processed_data.anomaly_metric} = {processed_data.anomaly_value}")
                    
                    # ì„¼ì„œ ë°ì´í„° ì´ë²¤íŠ¸ ë°œí–‰
                    await self.kafka_publisher.publish_sensor_data(processed_data)
                    
                except Exception as e:
                    logger.error(f"Mock ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜ ({raw_data.equipment_id}): {e}")
                    continue
            
            logger.info(f"Mock ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {processed_count}ê°œ ì²˜ë¦¬ë¨, {anomaly_count}ê°œ ì´ìƒì¹˜ íƒì§€")
            
        except Exception as e:
            logger.error(f"Mock ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    async def force_process(self):
        """ê°•ì œë¡œ Mock ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        if not self.is_running:
            logger.warning("Mock Data Schedulerê°€ ì‹¤í–‰ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤.")
            return
        
        await self._process_mock_data()
    
    def get_status(self):
        """ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "is_running": self.is_running,
            "polling_interval_seconds": self.data_fetch_interval,
            "last_check": datetime.utcnow().isoformat() if self.is_running else None
        }
